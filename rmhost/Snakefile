#!/usr/bin/env snakemake
from snakemake.utils import min_version
import pysam
import os
import pandas as pd
from pprint import pprint

min_version("5.0")

HG19FULL_SOAP_INDEX_PREFIX    = "/hwfssz1/ST_META/share/database/human/hg19/Hg19.fa.index"
HG38FULL_SOAP_INDEX_PREFIX    = "/ldfssz1/ST_META/share/User/zhujie/database/galaxy_indexes/hg38/hg38full/soap_index/hg38full.fa.index"
HG19_BWA_INDEX_PREFIX         = "/ldfssz1/ST_META/share/User/zhujie/database/galaxy_indexes/hg19/hg19full/bwa_index/hg19full.fa"
HG38FULL_BWA_INDEX_PREFIX     = "/ldfssz1/ST_META/share/User/zhujie/database/galaxy_indexes/hg38/hg38full/bwa_index/hg38full.fa"
HG38FULL_BBMAP_INDEX_FA       = "/ldfssz1/ST_META/share/User/zhujie/database/galaxy_indexes/hg38/hg38full/bbmap_index/hg38full.fa"
HG38FULL_BOWTIE2_INDEX_PREFIX = "/ldfssz1/ST_META/share/User/zhujie/database/galaxy_indexes/hg38/hg38full/bowtie2_index/hg38full"

def parse_samples(samples_tsv):
    return pd.read_csv(samples_tsv, sep='\s+').set_index('id', drop=False).to_dict(orient='index')

'''
SAMPLES = {
    "gy450g.1w" : {
        "r1": "data/gy450g.1w.fp.1.fq.gz",
        "r2": "data/gy450g.1w.fp.2.fq.gz"
    },
    "gy450g.10w" : {
        "r1": "data/gy450g.10w.fp.1.fq.gz",
        "r2": "data/gy450g.10w.fp.2.fq.gz"
    },
    "gy450g.100w" : {
        "r1": "data/gy450g.100w.fp.1.fq.gz",
        "r2": "data/gy450g.100w.fp.2.fq.gz"
    },
    "gy450g.1000w" : {
        "r1": "data/gy450g.1000w.fp.1.fq.gz",
        "r2": "data/gy450g.1000w.fp.2.fq.gz"
    },
    "RDPYD18189937_A_saliva.956w" : {
        "r1": "data/RDPYD18189937_A_saliva.956w.fp.1.fq.gz",
        "r2": "data/RDPYD18189937_A_saliva.956w.fp.2.fq.gz"
    },
    "RSZYD18093181_A_togue.862w" : {
        "r1": "data/RSZYD18093181_A_togue.862w.fp.1.fq.gz",
        "r2": "data/RSZYD18093181_A_togue.862w.fp.2.fq.gz"
    }
}
'''

SAMPLES = parse_samples("samples.tsv")
pprint(SAMPLES)


MAPPER = ["gyl_soap", "metapi_bwa_f12F256", "metapi_bwa_f4", "metapi_bwa_idfilter", "atlas_bbmap", "sunbeam_bwa", "anvio_bowtie2"]

rule all:
    input:
        expand([os.path.join("results", "{sample}.{mapper}.rmhost.{read}.fq.gz"),
                os.path.join("results", "{sample}.sunbeam_bwa_F4.hg38full.sorted.bam"),
                os.path.join("results", "{sample}.metapi_bwa_f4.hg38full.sorted.bam"),
                os.path.join("results", "{sample}.metapi_bwa_f12F256.hg38full.sorted.bam"),
                os.path.join("results", "{sample}.anvio_bowtie2_no-unal_F4.hg38full.sorted.bam"),
                os.path.join("results", "{sample}.sunbeam_bwa.flagstat.txt"),
                os.path.join("results", "{sample}.sunbeam_bwa.bamstats.txt"),
                os.path.join("results", "{sample}.{mapper}.rmhost.reads.count.txt"),
                os.path.join("results", "rmhost.reads.count.tsv"),
                os.path.join("benchmark", "rmhost.benchmark.tsv")],
               sample=SAMPLES,
               read=["1", "2"],
               mapper=MAPPER)

rule rmhost_gyl_soap:
    input:
        r1 = lambda wildcards: SAMPLES[wildcards.sample]["r1"],
        r2 = lambda wildcards: SAMPLES[wildcards.sample]["r2"],
        index = expand("{prefix}.{suffix}",
                       prefix=HG38FULL_SOAP_INDEX_PREFIX,
                       suffix=["amb", "ann", "bwt", "fmv", "hot", "lkt", "pac",
                               "rev.bwt", "rev.fmv", "rev.lkt", "rev.pac", "sa"])
    output:
        r1 = os.path.join("results", "{sample}.gyl_soap.rmhost.1.fq.gz"),
        r2 = os.path.join("results", "{sample}.gyl_soap.rmhost.2.fq.gz")
    log:
        "logs/{sample}.gyl_soap.rmhost.log"
    params:
        index_prefix = HG38FULL_SOAP_INDEX_PREFIX,
        output_prefix = os.path.join("results", "{sample}.gyl_soap")
    benchmark:
        "benchmark/{sample}.gyl_soap.rmhost.benchmark.txt"
    threads:
        8
    shell:
        '''
        perl bin/rmhost.pl -a {input.r1} -b {input.r2} \
        -d {params.index_prefix} -q 1 -p {params.output_prefix} -t {threads} 2> {log}
        '''


# http://seqanswers.com/forums/showthread.php?t=3342
# bwa mem
# bwa bwasw
# bwa aln
# bwa samse
# bwa sampe
# choose which?
# how to set parameter?
# https://www.biostars.org/p/12052/
# http://picard.sourceforge.net/explain-flags.html
# https://sourceforge.net/p/bio-bwa/mailman/message/31968535/
rule rmhost_metapi_bwa_f4:
    input:
        r1 = lambda wildcards: SAMPLES[wildcards.sample]["r1"],
        r2 = lambda wildcards: SAMPLES[wildcards.sample]["r2"],
        index = expand("{prefix}.{suffix}",
                       prefix=HG38FULL_BWA_INDEX_PREFIX,
                       suffix=["amb", "ann", "bwt", "pac", "sa"])
    output:
        flagstat = os.path.join("results", "{sample}.metapi_bwa_f4.flagstat.txt"),
        bamstats = os.path.join("results", "{sample}.metapi_bwa_f4.bamstats.txt"),
        bam = os.path.join("results", "{sample}.metapi_bwa_f4.hg38full.sorted.bam"),
        r1= os.path.join("results", "{sample}.metapi_bwa_f4.rmhost.1.fq.gz"),
        r2= os.path.join("results", "{sample}.metapi_bwa_f4.rmhost.2.fq.gz")
    log:
        "logs/{sample}.metapi_bwa_f4.rmhost.log"
    params:
        index_prefix = HG38FULL_BWA_INDEX_PREFIX
    benchmark:
        "benchmark/{sample}.metapi_bwa_f4.rmhost.benchmark.txt"
    threads:
        8
    shell:
        '''
        bwa mem -t {threads} {params.index_prefix} {input.r1} {input.r2} |
        tee >(samtools flagstat -@{threads} - > {output.flagstat}) |
        tee >(samtools stats -@{threads} - > {output.bamstats}) |
        tee >(samtools fastq -@{threads} -f 4 -1 {output.r1} -2 {output.r2} -) |
        samtools sort -b -@{threads} - -o {output.bam} 2> {log}
        '''

rule rmhost_metapi_bwa_f12F256:
    input:
        r1 = lambda wildcards: SAMPLES[wildcards.sample]["r1"],
        r2 = lambda wildcards: SAMPLES[wildcards.sample]["r2"],
        index = expand("{prefix}.{suffix}",
                       prefix=HG38FULL_BWA_INDEX_PREFIX,
                       suffix=["amb", "ann", "bwt", "pac", "sa"])
    output:
        flagstat = os.path.join("results", "{sample}.metapi_bwa_f12F256.flagstat.txt"),
        bamstats = os.path.join("results", "{sample}.metapi_bwa_f12F256.bamstats.txt"),
        bam = os.path.join("results", "{sample}.metapi_bwa_f12F256.hg38full.sorted.bam"),
        r1 = os.path.join("results", "{sample}.metapi_bwa_f12F256.rmhost.1.fq.gz"),
        r2 = os.path.join("results", "{sample}.metapi_bwa_f12F256.rmhost.2.fq.gz")
    log:
        "logs/{sample}.metapi_bwa_f12F256.rmhost.log"
    params:
        index_prefix = HG38FULL_BWA_INDEX_PREFIX
    benchmark:
        "benchmark/{sample}.metapi_bwa_f12F256.rmhost.benchmark.txt"
    threads:
        8
    shell:
        '''
        bwa mem -t {threads} {params.index_prefix} {input.r1} {input.r2} |
        tee >(samtools flagstat -@{threads} - > {output.flagstat}) |
        tee >(samtools stats -@{threads} - > {output.bamstats}) |
        tee >(samtools fastq -@{threads} -f 12 -F 256 -1 {output.r1} -2 {output.r2} -) |
        samtools sort -b -@{threads} - -o {output.bam} 2> {log}
        '''

# http://seqanswers.com/forums/showthread.php?t=58473
rule rmhost_metapi_bwa_idfilter:
    input:
        r1 = lambda wildcards: SAMPLES[wildcards.sample]["r1"],
        r2 = lambda wildcards: SAMPLES[wildcards.sample]["r2"],
        index = expand("{prefix}.{suffix}",
                       prefix=HG38FULL_BWA_INDEX_PREFIX,
                       suffix=["amb", "ann", "bwt", "pac", "sa"])
    output:
        flagstat = os.path.join("results", "{sample}.metapi_bwa_idfilter.flagstat.txt"),
        bamstats = os.path.join("results", "{sample}.metapi_bwa_idfilter.bamstats.txt"),
        bam = os.path.join("results", "{sample}.metapi_bwa_idfilter.hg38full.sorted.bam"),
        r1 = os.path.join("results", "{sample}.metapi_bwa_idfilter.rmhost.1.fq.gz"),
        r2 = os.path.join("results", "{sample}.metapi_bwa_idfilter.rmhost.2.fq.gz")
    log:
        "logs/{sample}.metapi_bwa_idfilter.rmhost.log"
    params:
        index_prefix = HG38FULL_BWA_INDEX_PREFIX,
        identity = 0.9
    benchmark:
        "benchmark/{sample}.metapi_bwa_idfilter.rmhost.benchmark.txt"
    threads:
        8
    shell:
        '''
        bwa mem -t {threads} {params.index_prefix} {input.r1} {input.r2} |
        tee >(samtools flagstat -@{threads} - > {output.flagstat}) |
        tee >(samtools stats -@{threads} - > {output.bamstats}) |
        tee >(samtools sort -b -@{threads} - -o {output.bam} 2> {log}) |
        awk -v maxpct={params.identity} -v OFS='\t' -v FS='\t' \
        '{ \
           if ($0 ~ /^@/) {print $0} \
           else \
           { \
             xnm=gensub(/.*\tNM:I:/, "", "g", $0); \
             nm=gensub(/\t.*/, "", "g", xnm); \
             pct=nm/length($10); \
             if (pct < maxpct) {print $0, "XP:f:"pct} \
           } \
        }' |
        samtools fastq -@{threads} -f 12 -F 256 -1 {output.r1} -2 {output.r2} -
        '''

# https://github.com/metagenome-atlas/atlas/blob/master/atlas/rules/qc.snakefile#L311
# http://seqanswers.com/forums/showthread.php?t=42552
JAVA_MEM = 32
JAVA_MEM_FRACTION = 0.85

CONTAMINANT_MAX_INDEL = 20
CONTAMINANT_MIN_RATIO = 0.65
CONTAMINANT_MINIMUM_HITS = 1
CONTAMINANT_AMBIGUOUS = "best"
CONTAMINANT_KMER_LENGTH = 13

rule bbmap_index_host_db:
    input:
        HG38FULL_BBMAP_INDEX_FA
    output:
        os.path.join(os.path.dirname(HG38FULL_BBMAP_INDEX_FA), "ref/genome/1/summary.txt")
    threads:
        8
    resources:
        mem = JAVA_MEM,
        java_mem = int(JAVA_MEM * JAVA_MEM_FRACTION)
    log:
        "logs/atlas_bbmap_index_hg38full_db.log"
    params:
        k = CONTAMINANT_KMER_LENGTH
    shell:
        '''
        bbmap.sh -Xmx{resources.java_mem}G ref={input} threads={threads} k={params.k} local=t 2> {log}
        '''

rule rmhost_atlas_bbmap:
    input:
        r1 = lambda wildcards: SAMPLES[wildcards.sample]["r1"],
        r2 = lambda wildcards: SAMPLES[wildcards.sample]["r2"],
        host_fa = HG38FULL_BBMAP_INDEX_FA
    output:
        r1 = os.path.join("results", "{sample}.atlas_bbmap.rmhost.1.fq.gz"),
        r2 = os.path.join("results", "{sample}.atlas_bbmap.rmhost.2.fq.gz"),
        stats = os.path.join("results", "{sample}.atlas_bbmap.reference_stats.txt")
    benchmark:
        "benchmark/{sample}.atlas_bbmap.rmhost.benchmark.txt"
    params:
        contaminant_folder = "results/host_atlas/{sample}",
        maxindel = CONTAMINANT_MAX_INDEL,
        minratio = CONTAMINANT_MIN_RATIO,
        minhits = CONTAMINANT_MINIMUM_HITS,
        ambiguous = CONTAMINANT_AMBIGUOUS,
        k = CONTAMINANT_KMER_LENGTH
    log:
        "logs/{sample}.atlas_bbmap.rmhost.log"
    threads:
        8
    resources:
        mem = 32,
        java_mem = int(JAVA_MEM * JAVA_MEM_FRACTION)
    shell:
        '''
        bbsplit.sh ref={input.host_fa} in1={input.r1} in2={input.r2} \
            outu1={output.r1} outu2={output.r2} \
            basename="{params.contaminant_folder}/%_#.fq.gz" \
            maxindel={params.maxindel} minratio={params.minratio} \
            minhits={params.minhits} ambiguous={params.ambiguous} refstats={output.stats} \
            threads={threads} k={params.k} local=t \
            -Xmx{resources.java_mem}G 2> {log}
        '''

# https://github.com/sunbeam-labs/sunbeam/blob/dev/rules/qc/decontaminate.rules
rule rmhost_sunbeam_bwa:
    input:
        r1 = lambda wildcards: SAMPLES[wildcards.sample]["r1"],
        r2 = lambda wildcards: SAMPLES[wildcards.sample]["r2"],
        index = expand("{prefix}.{suffix}",
                       prefix=HG38FULL_BWA_INDEX_PREFIX,
                       suffix=["amb", "ann", "bwt", "pac", "sa"])
    output:
        bam = os.path.join("results", "{sample}.sunbeam_bwa_F4.hg38full.sorted.bam"),
        flagstat = os.path.join("results", "{sample}.sunbeam_bwa.flagstat.txt"),
        bamstats = os.path.join("results", "{sample}.sunbeam_bwa.bamstats.txt")
    benchmark:
        "benchmark/{sample}.sunbeam_bwa.rmhost.benchmark.txt"
    params:
        index_prefix = HG38FULL_BWA_INDEX_PREFIX
    log:
        "logs/{sample}.sunbeam_bwa.rmhost.log"
    threads:
        8
    shell:
        '''
        bwa mem -M -t {threads} {params.index_prefix} {input.r1} {input.r2} |
        tee >(samtools flagstat -@{threads} - > {output.flagstat}) |
        tee >(samtools stats -@{threads} - > {output.bamstats}) |
        samtools view -@{threads} -hSF4 - |
        samtools sort -b -@{threads} -o {output.bam} - 2> {log}
        '''

# https://github.com/sunbeam-labs/sunbeam/blob/dev/sunbeamlib/decontam.py
PCT_ID = 0.5
FRAC = 0.6

def get_mapped_reads(fp, min_pct_id, min_len_frac):
    sam = pysam.AlignmentFile(fp)
    for read in sam:
        if ((not read.is_unmapped) and
            (_get_frac(read) > min_len_frac) and
            (_get_pct_identity(read) > min_pct_id)):
            yield read.query_name

def _get_pct_identity(read):
    if read.has_tag("NM"):
        edit_dist = read.get_tag("NM")
    else:
        edit_dist = 0
    pct_mm = float(edit_dist) / read.alen
    return 1 - pct_mm

def _get_frac(read):
    cigar = read.cigartuples
    clip = 0
    for pair in cigar:
        if pair[0] == 4 or pair[0] == 5:
            clip = clip + pair[1]
    frac = float(read.query_alignment_length)/(read.query_alignment_length + clip)
    return frac

rule sunbeam_get_mapped_reads_id:
    input:
        bam = os.path.join("results", "{sample}.sunbeam_bwa_F4.hg38full.sorted.bam")
    output:
        mapped_ids = os.path.join("results", "{sample}.sunbeam_bwa.mapped.ids")
    params:
        pct_id = PCT_ID,
        frac = FRAC
    run:
        with open(output.mapped_ids, 'w') as out:
            last = None
            for read_id in get_mapped_reads(input.bam, params.pct_id, params.frac):
                if read_id == last:
                    continue
                else:
                    out.write(read_id + '\n')
                    last = read_id

rule rmhost_sunbeam_get_unmapped_reads_1:
    input:
        mapped_ids = os.path.join("results", "{sample}.sunbeam_bwa.mapped.ids"),
        reads = lambda wildcards: SAMPLES[wildcards.sample]["r1"]
    output:
        reads = os.path.join("results", "{sample}.sunbeam_bwa.rmhost.1.fq.gz"),
    log:
        "logs/{sample}.sunbeam_filter_r1.rmhost.log"
    threads:
        8
    shell:
        '''
        pigz -p {threads} -dc {input.reads} |
        rbt fastq-filter {input.mapped_ids} |
        pigz -p {threads} - > {output.reads} 2> {log}
        '''

rule rmhost_sunbeam_get_unmapped_reads_2:
    input:
        mapped_ids = os.path.join("results", "{sample}.sunbeam_bwa.mapped.ids"),
        reads = lambda wildcards: SAMPLES[wildcards.sample]["r2"]
    output:
        reads = os.path.join("results", "{sample}.sunbeam_bwa.rmhost.2.fq.gz")
    log:
        "logs/{sample}.sunbeam_filter_r2.rmhost.log"
    threads:
        8
    shell:
        '''
        pigz -p {threads} -dc {input.reads} |
        rbt fastq-filter {input.mapped_ids} |
        pigz -p {threads} - > {output.reads} 2> {log}
        '''

# https://github.com/merenlab/anvio/issues/1011
# https://github.com/merenlab/anvio/pull/1025
# https://github.com/merenlab/anvio/blob/master/anvio/workflows/metagenomics/Snakefile#L691
# https://github.com/merenlab/anvio/blob/master/anvio/workflows/metagenomics/__init__.py#L136
# https://github.com/BenLangmead/bowtie2/issues/70
rule rmhost_anvio_bowtie2:
    input:
        r1 = lambda wildcards: SAMPLES[wildcards.sample]["r1"],
        r2 = lambda wildcards: SAMPLES[wildcards.sample]["r2"]
    output:
        bam = os.path.join("results", "{sample}.anvio_bowtie2_no-unal_F4.hg38full.sorted.bam"),
        bai = os.path.join("results", "{sample}.anvio_bowtie2_no-unal_F4.hg38full.sorted.bam.bai"),
        mapped_ids = os.path.join("results", "{sample}.anvio_bowtie2.mapped.ids")
    params:
        host_index_prefix = HG38FULL_BOWTIE2_INDEX_PREFIX,
        additional_params = "--no-unal"
    benchmark:
        "benchmark/{sample}.anvio_bowtie2.rmhost.benchmark.txt"
    log:
       "logs/{sample}.anvio_bowtie2.rmhost.log"
    threads:
        8
    shell:
        '''
        bowtie2 --threads {threads} -x {params.host_index_prefix} -1 {input.r1} -2 {input.r2} {params.additional_params} |
        samtools view -@{threads} -hSF4 - |
        samtools sort -b -@{threads} -o {output.bam} - 2> {log}
        samtools index -@{threads} {output.bam}
        samtools view {output.bam} | cut -f 1 | sort | uniq > {output.mapped_ids}
        '''

rule rmhost_anvio_get_unmapped_reads_1:
    input:
        reads = lambda wildcards: SAMPLES[wildcards.sample]["r1"],
        mapped_ids = os.path.join("results", "{sample}.anvio_bowtie2.mapped.ids")
    output:
        reads = os.path.join("results", "{sample}.anvio_bowtie2.rmhost.1.fq.gz"),
        reads_host = os.path.join("results", "{sample}.anvio_bowtie2.host.1.fq.gz"),
        reads_unzip = temp(os.path.join("results", "{sample}.anvio_bowtie2.unzip.1.fq")),
        survived = temp(os.path.join("results", "{sample}.anvio_bowtie2.unzip.1.fq.survived")),
        removed = temp(os.path.join("results", "{sample}.anvio_bowtie2.unzip.1.fq.removed"))
    params:
        delimiter = " ",
    log:
        "logs/{sample}.anvio_get_unmapped_r1.log"
    threads:
        8
    shell:
        '''
        pigz -p {threads} -dc {input.reads} > {output.reads_unzip}
        iu-remove-ids-from-fastq -i {output.reads_unzip} -l {input.mapped_ids} -d "{params.delimiter}" 2> {log}
        pigz -p {threads} {output.survived}
        pigz -p {threads} {output.removed}
        mv {output.survived} {output.reads}
        mv {output.removed} {output.reads_host}
        '''

rule rmhost_anvio_get_unmapped_reads_2:
    input:
        reads = lambda wildcards: SAMPLES[wildcards.sample]["r2"],
        mapped_ids = os.path.join("results", "{sample}.anvio_bowtie2.mapped.ids")
    output:
        reads = os.path.join("results", "{sample}.anvio_bowtie2.rmhost.2.fq.gz"),
        reads_host = os.path.join("results", "{sample}.anvio_bowtie2.host.2.fq.gz"),
        reads_unzip = temp(os.path.join("results", "{sample}.anvio_bowtie2.unzip.2.fq")),
        survived = temp(os.path.join("results", "{sample}.anvio_bowtie2.unzip.2.fq.survived")),
        removed = temp(os.path.join("results", "{sample}.anvio_bowtie2.unzip.2.fq.removed"))
    params:
        delimiter = " ",
    log:
        "logs/{sample}.anvio_get_unmapped_r2.log"
    threads:
        8
    shell:
        '''
        pigz -p {threads} -dc {input.reads} > {output.reads_unzip}
        iu-remove-ids-from-fastq -i {output.reads_unzip} -l {input.mapped_ids} -d "{params.delimiter}" 2> {log}
        pigz -p {threads} {output.survived}
        pigz -p {threads} {output.removed}
        mv {output.survived} {output.reads}
        mv {output.removed} {output.reads_host}
        '''

rule rmhost_reads_count:
    input:
        os.path.join("results", "{sample}.{mapper}.rmhost.1.fq.gz"),
    output:
        os.path.join("results", "{sample}.{mapper}.rmhost.reads.count.txt")
    threads:
        8
    shell:
        '''
        echo "reads_count" > {output}
        pigz -p {threads} -dc {input} | wc -l | xargs -I xxx expr xxx / 4 >> {output}
        '''

def change(table, mapper_, sample_):
    df = pd.DataFrame()
    df = pd.read_csv(table, sep='\s+')
    df.insert(loc=0, column='mapper', value=[mapper_])
    df.insert(loc=0, column='sample', value=[sample_])
    return df

rule merge_benchmark:
    input:
        expand(os.path.join("benchmark", "{sample}.{mapper}.rmhost.benchmark.txt"),
               sample=SAMPLES,
               mapper=MAPPER)
    output:
        rmhost_benchmark = os.path.join("benchmark", "rmhost.benchmark.tsv")
    run:
        df = pd.DataFrame()
        for benchmark in input:
            sample_ = os.path.basename(benchmark).split('.')[0]
            mapper_ = os.path.basename(benchmark).split('.')[1]


            df_ = change(benchmark, mapper_, sample_)
            df = pandas.concat([df, df_])

        df.to_csv(output.rmhost_benchmark, sep='\t', index=False)

rule merge_rmhost_reads_count:
    input:
        expand("results/{sample}.{mapper}.rmhost.reads.count.txt",
               sample=SAMPLES,
               mapper=MAPPER)
    output:
        rmhost_reads_cout = os.path.join("results", "rmhost.reads.count.tsv")
    run:
        df = pandas.DataFrame()

        for reads_count in input:
            sample_ = os.path.basename(benchmark).split('.')[0]
            mapper_ = os.path.basename(benchmark).split('.')[1]

            df_ = change(reads_count, mapper_, sample_)
            df = pandas.concat([df, df_])

        df.to_csv(output.rmhost_reads_count, sep='\t', index=False)
