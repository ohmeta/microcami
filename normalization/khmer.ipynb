{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#\n",
      "# This file is part of khmer, https://github.com/dib-lab/khmer/, and is\n",
      "# Copyright (C) 2013-2015, Michigan State University.\n",
      "# Copyright (C) 2015, The Regents of the University of California.\n",
      "#\n",
      "# Redistribution and use in source and binary forms, with or without\n",
      "# modification, are permitted provided that the following conditions are\n",
      "# met:\n",
      "#\n",
      "#     * Redistributions of source code must retain the above copyright\n",
      "#       notice, this list of conditions and the following disclaimer.\n",
      "#\n",
      "#     * Redistributions in binary form must reproduce the above\n",
      "#       copyright notice, this list of conditions and the following\n",
      "#       disclaimer in the documentation and/or other materials provided\n",
      "#       with the distribution.\n",
      "#\n",
      "#     * Neither the name of the Michigan State University nor the names\n",
      "#       of its contributors may be used to endorse or promote products\n",
      "#       derived from this software without specific prior written\n",
      "#       permission.\n",
      "#\n",
      "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n",
      "# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n",
      "# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n",
      "# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n",
      "# HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n",
      "# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n",
      "# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n",
      "# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n",
      "# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
      "# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "#\n",
      "# Contact: khmer-project@idyll.org\n",
      "#\n",
      "set -e # exit as soon as one command fails\n",
      "set -x # echo commands before executing them\n",
      "load-into-counting.py -x 1e8 -k 20 stamps-reads.ct \\\n",
      "\n",
      "abundance-dist.py stamps-reads.ct ../../data/stamps-reads.fa.gz \\\n",
      "\tstamps-reads.hist\n",
      "normalize-by-median.py -k 20 -C 10 -x 1e8 ../../data/stamps-reads.fa.gz \\\n",
      "\t--savegraph stamps-dn.ct\n",
      "abundance-dist.py stamps-dn.ct stamps-reads.fa.gz.keep stamps-dn.hist\n",
      "do-partition.py -k 32 -x 1e8 -s 1e4 -T 8 stamps-part \\\n",
      "\t../../data/stamps-reads.fa.gz\n",
      "../../sandbox/error-correct-pass2.py --trusted-cov 10 stamps-dn.ct \\\n",
      "\t../../data/stamps-reads.fa.gz\n",
      "load-into-counting.py -x 1e8 -k 20 stamps-corr.ct stamps-reads.fa.gz.corr\n",
      "abundance-dist.py stamps-corr.ct stamps-reads.fa.gz.corr stamps-corr.hist\n",
      "extract-partitions.py stamps-part stamps-reads.fa.gz.part\n",
      "extract-partitions.py -X 1 stamps-part stamps-reads.fa.gz.part\n",
      "load-into-counting.py -x 1e8 -k 20 stamps-part.g0.ct stamps-part.group0000.fa\n",
      "load-into-counting.py -x 1e8 -k 20 stamps-part.g1.ct stamps-part.group0001.fa\n",
      "abundance-dist.py stamps-part.g0.ct stamps-part.group0000.fa stamps-part.g0.hist\n",
      "abundance-dist.py stamps-part.g1.ct stamps-part.group0001.fa stamps-part.g1.hist\n",
      "\n",
      "filter-abund.py stamps-dn.ct stamps-reads.fa.gz.keep\n",
      "normalize-by-median.py -x 1e8 -k 20 -C 10 stamps-reads.fa.gz.keep.abundfilt \\\n",
      "\t--savegraph stamps-dn3.ct\n",
      "\n",
      "abundance-dist.py stamps-dn3.ct stamps-reads.fa.gz.keep.abundfilt.keep \\\n",
      "\tstamps-dn3.hist\n"
     ]
    }
   ],
   "source": [
    "!cat /ldfssz1/ST_META/share/User/zhujie/toolkit/khmer/examples/stamps/do.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script filter-abund.py in khmer.\n",
      "|| You are running khmer version 3.0.0a1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||   * Q Zhang et al., http://dx.doi.org/10.1371/journal.pone.0101271\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "usage: filter-abund.py [--version] [--info] [-h] [-T THREADS] [-C CUTOFF] [-V]\n",
      "                       [-Z NORMALIZE_TO] [-o optional_output_filename] [-f]\n",
      "                       [-q] [--gzip | --bzip]\n",
      "                       input_count_graph_filename input_sequence_filename\n",
      "                       [input_sequence_filename ...]\n",
      "\n",
      "Trim sequences at a minimum k-mer abundance.\n",
      "\n",
      "positional arguments:\n",
      "  input_count_graph_filename\n",
      "                        The input k-mer countgraph filename\n",
      "  input_sequence_filename\n",
      "                        Input FAST[AQ] sequence filename\n",
      "\n",
      "optional arguments:\n",
      "  --version             show program's version number and exit\n",
      "  --info                print citation information\n",
      "  -h, --help            show this help message and exit\n",
      "  -T THREADS, --threads THREADS\n",
      "                        Number of simultaneous threads to execute (default: 1)\n",
      "  -C CUTOFF, --cutoff CUTOFF\n",
      "                        Trim at k-mers below this abundance. (default: 2)\n",
      "  -V, --variable-coverage\n",
      "                        Only trim low-abundance k-mers from sequences that\n",
      "                        have high coverage. (default: False)\n",
      "  -Z NORMALIZE_TO, --normalize-to NORMALIZE_TO\n",
      "                        Base the variable-coverage cutoff on this median k-mer\n",
      "                        abundance. (default: 20)\n",
      "  -o optional_output_filename, --output optional_output_filename\n",
      "                        Output the trimmed sequences into a single file with\n",
      "                        the given filename instead of creating a new file for\n",
      "                        each input file. (default: None)\n",
      "  -f, --force           Overwrite output file if it exists (default: False)\n",
      "  -q, --quiet\n",
      "  --gzip                Compress output using gzip (default: False)\n",
      "  --bzip                Compress output using bzip2 (default: False)\n",
      "\n",
      "Trimmed sequences will be placed in \"${input_sequence_filename}.abundfilt\" for\n",
      "each input sequence file. If the input sequences are from RNAseq or metagenome\n",
      "sequencing then `--variable-coverage` should be used.\n",
      "\n",
      "Example:\n",
      "\n",
      "    load-into-counting.py -k 20 -x 5e7 countgraph data/100k-filtered.fa\n",
      "    filter-abund.py -C 2 countgraph data/100k-filtered.fa\n"
     ]
    }
   ],
   "source": [
    "!filter-abund.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script normalize-by-median.py in khmer.\n",
      "|| You are running khmer version 3.0.0a1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||   * CT Brown et al., arXiv:1203.4802 [q-bio.GN]\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "usage: normalize-by-median.py [--version] [--info] [-h] [-k KSIZE]\n",
      "                              [-U UNIQUE_KMERS] [--fp-rate FP_RATE]\n",
      "                              [-M MAX_MEMORY_USAGE] [--small-count] [-q]\n",
      "                              [-C CUTOFF] [-p] [--force_single]\n",
      "                              [-u unpaired_reads_filename] [-s filename]\n",
      "                              [-R report_filename]\n",
      "                              [--report-frequency report_frequency] [-f]\n",
      "                              [-o filename] [-l filename] [--gzip | --bzip]\n",
      "                              input_sequence_filename\n",
      "                              [input_sequence_filename ...]\n",
      "\n",
      "Do digital normalization (remove mostly redundant sequences)\n",
      "\n",
      "positional arguments:\n",
      "  input_sequence_filename\n",
      "                        Input FAST[AQ] sequence filename.\n",
      "\n",
      "optional arguments:\n",
      "  --version             show program's version number and exit\n",
      "  --info                print citation information\n",
      "  -h, --help            show this help message and exit\n",
      "  -k KSIZE, --ksize KSIZE\n",
      "                        k-mer size to use (default: 32)\n",
      "  -U UNIQUE_KMERS, --unique-kmers UNIQUE_KMERS\n",
      "                        approximate number of unique kmers in the input set\n",
      "                        (default: 0)\n",
      "  --fp-rate FP_RATE     Override the automatic FP rate setting for the current\n",
      "                        script (default: None)\n",
      "  -M MAX_MEMORY_USAGE, --max-memory-usage MAX_MEMORY_USAGE\n",
      "                        maximum amount of memory to use for data structure\n",
      "                        (default: None)\n",
      "  --small-count         Reduce memory usage by using a smaller counter for\n",
      "                        individual kmers. (default: False)\n",
      "  -q, --quiet\n",
      "  -C CUTOFF, --cutoff CUTOFF\n",
      "                        when the median k-mer coverage level is above this\n",
      "                        number the read is not kept. (default: 20)\n",
      "  -p, --paired          require that all sequences be properly paired\n",
      "                        (default: False)\n",
      "  --force_single        treat all sequences as single-ended/unpaired (default:\n",
      "                        False)\n",
      "  -u unpaired_reads_filename, --unpaired-reads unpaired_reads_filename\n",
      "                        include a file of unpaired reads to which -p/--paired\n",
      "                        does not apply. (default: None)\n",
      "  -s filename, --savegraph filename\n",
      "                        save the k-mer countgraph to disk after all reads are\n",
      "                        loaded. (default: None)\n",
      "  -R report_filename, --report report_filename\n",
      "                        write progress report to report_filename (default:\n",
      "                        None)\n",
      "  --report-frequency report_frequency\n",
      "                        report progress every report_frequency reads (default:\n",
      "                        100000)\n",
      "  -f, --force           continue past file reading errors (default: False)\n",
      "  -o filename, --output filename\n",
      "                        only output a single file with the specified filename;\n",
      "                        use a single dash \"-\" to specify that output should go\n",
      "                        to STDOUT (the terminal) (default: None)\n",
      "  -l filename, --loadgraph filename\n",
      "                        load a precomputed k-mer graph from disk (default:\n",
      "                        None)\n",
      "  --gzip                Compress output using gzip (default: False)\n",
      "  --bzip                Compress output using bzip2 (default: False)\n",
      "\n",
      "Discard sequences based on whether or not their median k-mer abundance lies\n",
      "above a specified cutoff. Kept sequences will be placed in <fileN>.keep.\n",
      "\n",
      "By default, paired end reads will be considered together; if either read should\n",
      "be kept, both will be kept. (This keeps both reads from a fragment, and helps\n",
      "with retention of repeats.) Unpaired reads are treated individually.\n",
      "\n",
      "If `-p`/`--paired` is set, then proper pairing is required and the script will\n",
      "exit on unpaired reads, although `--unpaired-reads` can be used to supply a\n",
      "file of orphan reads to be read after the paired reads.\n",
      "\n",
      "`--force_single` will ignore all pairing information and treat reads\n",
      "individually.\n",
      "\n",
      "With `-s`/`--savegraph`, the k-mer countgraph will be saved to the specified\n",
      "file after all sequences have been processed. `-l`/`--loadgraph` will load the\n",
      "specified k-mer countgraph before processing the specified files.  Note that\n",
      "these graphs are are in the same format as those produced by `load-into-\n",
      "counting.py` and consumed by `abundance-dist.py`.\n",
      "\n",
      "To append reads to an output file (rather than overwriting it), send output to\n",
      "STDOUT with `--output -` and use UNIX file redirection syntax (`>>`) to append\n",
      "to the file.\n",
      "\n",
      "Example:\n",
      "\n",
      "    normalize-by-median.py -k 17 tests/test-data/test-abund-read-2.fa\n",
      "\n",
      "Example:\n",
      "\n",
      "    normalize-by-median.py -p -k 17 \\\n",
      "    tests/test-data/test-abund-read-paired.fa\n",
      "\n",
      "Example:\n",
      "\n",
      "    normalize-by-median.py -p -k 17 -o - tests/test-data/paired.fq \\\n",
      "    >> appended-output.fq\n",
      "\n",
      "Example:\n",
      "\n",
      "    normalize-by-median.py -k 17 -f tests/test-data/test-error-reads.fq \\\n",
      "    tests/test-data/test-fastq-reads.fq\n",
      "\n",
      "Example:\n",
      "\n",
      "    normalize-by-median.py -k 17 -s test.ct \\\n",
      "    tests/test-data/test-abund-read-2.fa \\\n",
      "    tests/test-data/test-fastq-reads.fq\n"
     ]
    }
   ],
   "source": [
    "!normalize-by-median.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script load-into-counting.py in khmer.\n",
      "|| You are running khmer version 3.0.0a1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||   * Q Zhang et al., http://dx.doi.org/10.1371/journal.pone.0101271\n",
      "||   * A. Döring et al. http://dx.doi.org:80/10.1186/1471-2105-9-11\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "usage: load-into-counting.py [--version] [--info] [-h] [-k KSIZE]\n",
      "                             [-U UNIQUE_KMERS] [--fp-rate FP_RATE]\n",
      "                             [-M MAX_MEMORY_USAGE] [--small-count]\n",
      "                             [-T THREADS] [-b] [-s FORMAT] [-f] [-q]\n",
      "                             output_countgraph_filename\n",
      "                             input_sequence_filename\n",
      "                             [input_sequence_filename ...]\n",
      "\n",
      "Build a k-mer countgraph from the given sequences.\n",
      "\n",
      "positional arguments:\n",
      "  output_countgraph_filename\n",
      "                        The name of the file to write the k-mer countgraph to.\n",
      "  input_sequence_filename\n",
      "                        The names of one or more FAST[AQ] input sequence\n",
      "                        files.\n",
      "\n",
      "optional arguments:\n",
      "  --version             show program's version number and exit\n",
      "  --info                print citation information\n",
      "  -h, --help            show this help message and exit\n",
      "  -k KSIZE, --ksize KSIZE\n",
      "                        k-mer size to use (default: 32)\n",
      "  -U UNIQUE_KMERS, --unique-kmers UNIQUE_KMERS\n",
      "                        approximate number of unique kmers in the input set\n",
      "                        (default: 0)\n",
      "  --fp-rate FP_RATE     Override the automatic FP rate setting for the current\n",
      "                        script (default: None)\n",
      "  -M MAX_MEMORY_USAGE, --max-memory-usage MAX_MEMORY_USAGE\n",
      "                        maximum amount of memory to use for data structure\n",
      "                        (default: None)\n",
      "  --small-count         Reduce memory usage by using a smaller counter for\n",
      "                        individual kmers. (default: False)\n",
      "  -T THREADS, --threads THREADS\n",
      "                        Number of simultaneous threads to execute (default: 1)\n",
      "  -b, --no-bigcount     The default behaviour is to count past 255 using\n",
      "                        bigcount. This flag turns bigcount off, limiting\n",
      "                        counts to 255. (default: True)\n",
      "  -s FORMAT, --summary-info FORMAT\n",
      "                        What format should the machine readable run summary be\n",
      "                        in? (`json` or `tsv`, disabled by default) (default:\n",
      "                        None)\n",
      "  -f, --force           Overwrite output file if it exists (default: False)\n",
      "  -q, --quiet\n",
      "\n",
      "Note: with `-b`/`--no-bigcount` the output will be the exact size of the k-mer\n",
      "countgraph and this script will use a constant amount of memory. In exchange\n",
      "k-mer counts will stop at 255. The memory usage of this script with `-b` will\n",
      "be about 1.15x the product of the `-x` and `-N` numbers.\n",
      "\n",
      "Example:\n",
      "\n",
      "    load-into-counting.py -k 20 -x 5e7 out data/100k-filtered.fa\n",
      "\n",
      "Multiple threads can be used to accelerate the process, if you have extra cores\n",
      "to spare.\n",
      "\n",
      "Example:\n",
      "\n",
      "    load-into-counting.py -k 20 -x 5e7 -T 4 out data/100k-filtered.fa\n"
     ]
    }
   ],
   "source": [
    "!load-into-counting.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script load-into-counting.py in khmer.\n",
      "|| You are running khmer version 3.0.0a1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||   * Q Zhang et al., http://dx.doi.org/10.1371/journal.pone.0101271\n",
      "||   * A. Döring et al. http://dx.doi.org:80/10.1186/1471-2105-9-11\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "\n",
      "PARAMETERS:\n",
      " - kmer size =     20 \t\t(-k)\n",
      " - n tables =      4 \t\t(-N)\n",
      " - max tablesize = 1e+08 \t(-x)\n",
      "Estimated memory usage is 0.4 Gb (4e+08 bytes = 4 bytes x 1e+08 entries / 1 entries per byte)\n",
      "--------\n",
      "Saving k-mer countgraph to ecoli_1K.reads.ct\n",
      "Loading kmers from sequences in ['ecoli_1K_1.fq.gz', 'ecoli_1K_2.fq.gz']\n",
      "making countgraph\n",
      "consuming input ecoli_1K_1.fq.gz\n",
      "consuming input ecoli_1K_2.fq.gz\n",
      "Total number of unique k-mers: 988\n",
      "saving ecoli_1K.reads.ct\n",
      "fp rate estimated to be 0.000\n",
      "DONE.\n",
      "wrote to: ecoli_1K.reads.ct.info\n"
     ]
    }
   ],
   "source": [
    "!load-into-counting.py -x1e8 -k 20 ecoli_1K.reads.ct ecoli_1K_1.fq.gz ecoli_1K_2.fq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: abundance-dist.py [--version] [--info] [-h] [-z] [-s] [-b] [-f] [-q]\n",
      "                         input_count_graph_filename input_sequence_filename\n",
      "                         output_histogram_filename\n",
      "abundance-dist.py: error: unrecognized arguments: ecoli_1K.hist\n"
     ]
    }
   ],
   "source": [
    "!abundance-dist.py ecoli_1K.reads.ct ecoli_1K_1.fq.gz ecoli_1K_2.fq.gz ecoli_1K.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script abundance-dist.py in khmer.\n",
      "|| You are running khmer version 3.0.0a1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||   * Q Zhang et al., http://dx.doi.org/10.1371/journal.pone.0101271\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "usage: abundance-dist.py [--version] [--info] [-h] [-z] [-s] [-b] [-f] [-q]\n",
      "                         input_count_graph_filename input_sequence_filename\n",
      "                         output_histogram_filename\n",
      "\n",
      "Calculate abundance distribution of the k-mers in the sequence file using a\n",
      "pre-made k-mer countgraph.\n",
      "\n",
      "positional arguments:\n",
      "  input_count_graph_filename\n",
      "                        The name of the input k-mer countgraph file.\n",
      "  input_sequence_filename\n",
      "                        The name of the input FAST[AQ] sequence file.\n",
      "  output_histogram_filename\n",
      "                        The columns are: (1) k-mer abundance, (2) k-mer count,\n",
      "                        (3) cumulative count, (4) fraction of total distinct\n",
      "                        k-mers.\n",
      "\n",
      "optional arguments:\n",
      "  --version             show program's version number and exit\n",
      "  --info                print citation information\n",
      "  -h, --help            show this help message and exit\n",
      "  -z, --no-zero         Do not output zero-count bins (default: True)\n",
      "  -s, --squash          Overwrite existing output_histogram_filename (default:\n",
      "                        False)\n",
      "  -b, --no-bigcount     Do not count k-mers past 255 (default: True)\n",
      "  -f, --force           Continue even if specified input files do not exist or\n",
      "                        are empty. (default: False)\n",
      "  -q, --quiet\n",
      "\n",
      "Example:\n",
      "\n",
      "    load-into-counting.py -x 1e7 -N 2 -k 17 counts \\\n",
      "            tests/test-data/test-abund-read-2.fa\n",
      "    abundance-dist.py counts tests/test-data/test-abund-read-2.fa test-dist\n"
     ]
    }
   ],
   "source": [
    "!abundance-dist.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script interleave-reads.py in khmer.\n",
      "|| You are running khmer version 3.0.0a1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "Interleaving:\n",
      "\tecoli_1K_1.fq.gz\n",
      "\tecoli_1K_2.fq.gz\n",
      "... 0 pairs\n",
      "final: interleaved 2054 pairs\n",
      "output written to ecoli_1K.paired.fq\n"
     ]
    }
   ],
   "source": [
    "!interleave-reads.py ecoli_1K_1.fq.gz ecoli_1K_2.fq.gz -o ecoli_1K.paired.fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 390649\n",
      "lrwxrwxrwx 1 zhujie ST_META        48 Dec  5 09:47 ecoli_1K_1.fq.gz -> ../assembly/spades_test_dataset/ecoli_1K_1.fq.gz\n",
      "lrwxrwxrwx 1 zhujie ST_META        48 Dec  5 09:47 ecoli_1K_2.fq.gz -> ../assembly/spades_test_dataset/ecoli_1K_2.fq.gz\n",
      "-rw-r--r-- 1 zhujie ST_META    852151 Dec  5 10:14 ecoli_1K.paired.fq\n",
      "-rw-r--r-- 1 zhujie ST_META 400005880 Dec  5 10:05 ecoli_1K.reads.ct\n",
      "-rw-r--r-- 1 zhujie ST_META       139 Dec  5 10:05 ecoli_1K.reads.ct.info\n",
      "lrwxrwxrwx 1 zhujie ST_META        57 Dec  4 15:11 examples -> /ldfssz1/ST_META/share/User/zhujie/toolkit/khmer/examples\n",
      "-rw-r--r-- 1 zhujie ST_META      7930 Dec  5 10:13 khmer.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@EAS20_8_6_1_9_1972/1 trim=6\n",
      "ACCACCATTACCACCACCATCACCATTACCACAGGTAACGGTGCGGGCTGACGCGTACAGGAAACACAGAAAAAAGCCCGCACCTGACAGTGCG\n",
      "+\n",
      "HHHHHHGHHHHFHHGGHHFHHHHHFHHFHFHHHHHFHHHHHFHHHHHHHHFHHFHFDHHGG@BGGHCDHE:;3)7.A973A:AA5>AD9G=D<D\n",
      "@EAS20_8_6_1_9_1972/2 correct\n",
      "GGTGGCCACCTGCCCCTGCCTGGCATTGCTTTCCAGAATATCGGCAACACGCAGAAAACGTTCTGCATTTGCCACTGATGTACCGCCGAACTTCAACACT\n",
      "+\n",
      "HFHHHGHHHHHHHHHHHHGHHHHHHGHHHHHHHHHHHFHHGHHGHEHHHHHHEH;G?F<F?GDFF/EEFBD:DCHHH7A@?EEH@HH96:4F@#76=C@@\n",
      "@EAS20_8_6_1_163_1521/1\n",
      "GCAGAAAACGTTCTGCATTTGCCACTGATGTACCGCCGAACTTCAACACTCGCATGGTTGTTACCTCGTTACCTTTGGTCGAAAAAAAAAGCCCGCACTG\n",
      "+\n",
      "HGHHIHHHDHHHHHIHHIHHHHHHHHHBHHHHHFHCFHHHHHHHGHHHHHEHHFHHHGHHIHHHGHGHHHIHFHHHHHGH?5<<;BD>6>?BGEHHGHFG\n",
      "@EAS20_8_6_1_163_1521/2\n",
      "GGCATAGCGCACAGACAGATAAAAATTACAGAGTACACAACATCCATGAAACGCATTAGCACCACCATTACCACCACCATCACCATTACCACAGGTAACG\n",
      "+\n",
      "HHGGFHHGHHHHHHHGFHHHHHHHCGHFHFHFHHHHHHGHHGHHDHHIEGEDFEHHCHHHHGCCGF>GFEFEGGFGGEIG1ACBCF?CD1?CADCD.DFB\n",
      "cat: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!cat ecoli_1K.paired.fq | head -16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@EAS20_8_6_1_9_1972/1 trim=6\n",
      "ACCACCATTACCACCACCATCACCATTACCACAGGTAACGGTGCGGGCTGACGCGTACAGGAAACACAGAAAAAAGCCCGCACCTGACAGTGCG\n",
      "+\n",
      "HHHHHHGHHHHFHHGGHHFHHHHHFHHFHFHHHHHFHHHHHFHHHHHHHHFHHFHFDHHGG@BGGHCDHE:;3)7.A973A:AA5>AD9G=D<D\n",
      "@EAS20_8_6_1_163_1521/1\n",
      "GCAGAAAACGTTCTGCATTTGCCACTGATGTACCGCCGAACTTCAACACTCGCATGGTTGTTACCTCGTTACCTTTGGTCGAAAAAAAAAGCCCGCACTG\n",
      "+\n",
      "HGHHIHHHDHHHHHIHHIHHHHHHHHHBHHHHHFHCFHHHHHHHGHHHHHEHHFHHHGHHIHHHGHGHHHIHFHHHHHGH?5<<;BD>6>?BGEHHGHFG\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat ecoli_1K_1.fq.gz | head -8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script load-into-counting.py in khmer.\n",
      "|| You are running khmer version 3.0.0a1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||   * Q Zhang et al., http://dx.doi.org/10.1371/journal.pone.0101271\n",
      "||   * A. Döring et al. http://dx.doi.org:80/10.1186/1471-2105-9-11\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "\n",
      "PARAMETERS:\n",
      " - kmer size =     20 \t\t(-k)\n",
      " - n tables =      4 \t\t(-N)\n",
      " - max tablesize = 1e+08 \t(-x)\n",
      "Estimated memory usage is 0.4 Gb (4e+08 bytes = 4 bytes x 1e+08 entries / 1 entries per byte)\n",
      "--------\n",
      "Saving k-mer countgraph to ecoli_1K.paired.reads.ct\n",
      "Loading kmers from sequences in ['ecoli_1K.paired.fq']\n",
      "making countgraph\n",
      "consuming input ecoli_1K.paired.fq\n",
      "Total number of unique k-mers: 988\n",
      "saving ecoli_1K.paired.reads.ct\n",
      "fp rate estimated to be 0.000\n",
      "DONE.\n",
      "wrote to: ecoli_1K.paired.reads.ct.info\n"
     ]
    }
   ],
   "source": [
    "!load-into-counting.py -x1e8 -k 20 ecoli_1K.paired.reads.ct ecoli_1K.paired.fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 780613\n",
      "lrwxrwxrwx 1 zhujie ST_META        48 Dec  5 09:47 ecoli_1K_1.fq.gz -> ../assembly/spades_test_dataset/ecoli_1K_1.fq.gz\n",
      "lrwxrwxrwx 1 zhujie ST_META        48 Dec  5 09:47 ecoli_1K_2.fq.gz -> ../assembly/spades_test_dataset/ecoli_1K_2.fq.gz\n",
      "-rw-r--r-- 1 zhujie ST_META    852151 Dec  5 10:14 ecoli_1K.paired.fq\n",
      "-rw-r--r-- 1 zhujie ST_META 400005880 Dec  5 10:15 ecoli_1K.paired.reads.ct\n",
      "-rw-r--r-- 1 zhujie ST_META       116 Dec  5 10:15 ecoli_1K.paired.reads.ct.info\n",
      "-rw-r--r-- 1 zhujie ST_META 400005880 Dec  5 10:05 ecoli_1K.reads.ct\n",
      "-rw-r--r-- 1 zhujie ST_META       139 Dec  5 10:05 ecoli_1K.reads.ct.info\n",
      "lrwxrwxrwx 1 zhujie ST_META        57 Dec  4 15:11 examples -> /ldfssz1/ST_META/share/User/zhujie/toolkit/khmer/examples\n",
      "-rw-r--r-- 1 zhujie ST_META      9811 Dec  5 10:15 khmer.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script abundance-dist.py in khmer.\n",
      "|| You are running khmer version 3.0.0a1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||   * Q Zhang et al., http://dx.doi.org/10.1371/journal.pone.0101271\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "Loading counting graph from ecoli_1K.reads.ct\n",
      "K: 20\n",
      "outputting to ecoli_1K.hist\n",
      "preparing hist...\n"
     ]
    }
   ],
   "source": [
    "!abundance-dist.py ecoli_1K.reads.ct ecoli_1K.paired.fq ecoli_1K.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script abundance-dist.py in khmer.\n",
      "|| You are running khmer version 3.0.0a1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||   * Q Zhang et al., http://dx.doi.org/10.1371/journal.pone.0101271\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "Loading counting graph from ecoli_1K.paired.reads.ct\n",
      "K: 20\n",
      "outputting to ecoli_1K.paired.hist\n",
      "preparing hist...\n"
     ]
    }
   ],
   "source": [
    "!abundance-dist.py ecoli_1K.paired.reads.ct ecoli_1K.paired.fq ecoli_1K.paired.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ecoli_1K.paired.hist == ecoli_1K.hist  nice! ^ ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoli_1K_1.fq.gz    ecoli_1K.paired.hist\t   ecoli_1K.reads.ct.info\n",
      "ecoli_1K_2.fq.gz    ecoli_1K.paired.reads.ct\t   examples\n",
      "ecoli_1K.hist\t    ecoli_1K.paired.reads.ct.info  khmer.ipynb\n",
      "ecoli_1K.paired.fq  ecoli_1K.reads.ct\n",
      "CPU times: user 6 ms, sys: 15 ms, total: 21 ms\n",
      "Wall time: 241 ms\n"
     ]
    }
   ],
   "source": [
    "%time !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script interleave-reads.py in khmer.\n",
      "|| You are running khmer version 3.0.0a1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "Interleaving:\n",
      "\tecoli_1K_1.fq.gz\n",
      "\tecoli_1K_2.fq.gz\n",
      "... 0 pairs\n",
      "final: interleaved 2054 pairs\n",
      "output written to ecoli_1K.paired.fq.pytest\n",
      "CPU times: user 34 ms, sys: 14 ms, total: 48 ms\n",
      "Wall time: 942 ms\n"
     ]
    }
   ],
   "source": [
    "%time !interleave-reads.py ecoli_1K_1.fq.gz ecoli_1K_2.fq.gz -o ecoli_1K.paired.fq.pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 14 ms, total: 18 ms\n",
      "Wall time: 266 ms\n"
     ]
    }
   ],
   "source": [
    "%time !seqtk mergepe ecoli_1K_1.fq.gz ecoli_1K_2.fq.gz > ecoli_1K.paired.fq.seqtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 9 ms, total: 17 ms\n",
      "Wall time: 332 ms\n"
     ]
    }
   ],
   "source": [
    "%time !seqtk mergepe ecoli_1K_1.fq.gz ecoli_1K_2.fq.gz | gzip - > ecoli_1K.paired.fq.seqtk.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 ms, sys: 11 ms, total: 17 ms\n",
      "Wall time: 254 ms\n"
     ]
    }
   ],
   "source": [
    "%time !seqtk mergepe ecoli_1K_1.fq.gz ecoli_1K_2.fq.gz | pigz - > ecoli_1K.paired.fq.seqtk.sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pigz: skipping: 8 does not exist\n",
      "CPU times: user 6 ms, sys: 14 ms, total: 20 ms\n",
      "Wall time: 298 ms\n"
     ]
    }
   ],
   "source": [
    "%time !seqtk mergepe ecoli_1K_1.fq.gz ecoli_1K_2.fq.gz | pigz -n 8 - > ecoli_1K.paired.fq.seqtk.sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
